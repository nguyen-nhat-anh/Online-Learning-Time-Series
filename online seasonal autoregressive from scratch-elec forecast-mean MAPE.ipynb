{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Seasonal Autoregressive model $(p, 0, 0)\\times(P,0,0)_s$ assumes the time series is generated according to the following model\n",
    "\n",
    "$$ \\phi(B) \\Phi(B^s) X_t = \\epsilon_t, \\tag{1} \\quad \\{\\epsilon_t\\} \\sim WN(0, \\sigma^2), \\label{eq:1}$$\n",
    "\n",
    "where\n",
    "\n",
    "$ \\phi(B) = 1 - \\overline{\\phi}(B), $\n",
    "\n",
    "$ \\Phi(B) = 1 - \\overline{\\Phi}(B^s), $\n",
    "\n",
    "$ \\overline{\\phi}(B) = \\phi_1 B + \\phi_2 B^2 + \\ldots + \\phi_p B^p , $\n",
    "\n",
    "$ \\overline{\\Phi}(B^s) = \\Phi_1 B^s + \\Phi_2 B^{2s} + \\ldots + \\Phi_P B^{Ps} , $\n",
    "\n",
    "* From equation $\\eqref{eq:1}$, $X_t$ is generated via the formula\n",
    "\n",
    "$$ X_t = \\overline{\\phi}(B) X_t + \\overline{\\Phi}(B^s) X_t - \\overline{\\phi}(B)\\overline{\\Phi}(B^s) X_t + \\epsilon_t $$\n",
    "\n",
    "* Prediction at time $t$ is calculated as\n",
    "\n",
    "$$\\tilde{X}_t = \\overline{\\phi}(B) X_t + \\overline{\\Phi}(B^s) X_t - \\overline{\\phi}(B)\\overline{\\Phi}(B^s) X_t$$\n",
    "\n",
    "* Squared loss function is defined as follows\n",
    "\n",
    "\\begin{align}\n",
    "f_t(\\phi, \\Phi) &= \\ell_t(X_t, \\tilde{X}_t (\\phi, \\Phi)) \\\\\n",
    "                &= (X_t - \\tilde{X}_t (\\phi, \\Phi))^2 \\\\\n",
    "                &= \\epsilon_t^2 \\\\\n",
    "                &= [\\phi(B) \\Phi(B^s) X_t]^2\n",
    "\\end{align}\n",
    "\n",
    "* Gradients of the loss function with respect to $\\phi$ and $\\Phi$ are calculated as\n",
    "\n",
    "$$ \\frac{\\partial f_t}{\\partial \\phi_i} = -2 (X_t - \\tilde{X}_t) B^i \\Phi(B^s) X_t, \\quad i=\\overline{1,p} $$\n",
    "$$ \\frac{\\partial f_t}{\\partial \\Phi_j} = -2 (X_t - \\tilde{X}_t) B^{js} \\phi(B) X_t, \\quad j=\\overline{1,P} $$\n",
    "$$ \\nabla_t = \\nabla f_t(\\phi, \\Phi) = (\\frac{\\partial f_t}{\\partial \\phi_1}, \\ldots, \\frac{\\partial f_t}{\\partial \\phi_p}, \\frac{\\partial f_t}{\\partial \\Phi_1}, \\ldots, \\frac{\\partial f_t}{\\partial \\Phi_P})^T $$\n",
    "\n",
    "* Seasonal ARMA Online Newton Step algorithm:\n",
    "\n",
    "Input: non-seasonal order $p$, seasonal order $P$, seasonal period $s$.\n",
    "\n",
    "Set \n",
    "\n",
    "$c = 1,$ \n",
    "\n",
    "$D = 2c \\cdot \\sqrt{p + P},$ \n",
    "\n",
    "$G = D \\cdot X_{max}^2,$\n",
    "\n",
    "$\\lambda = \\frac{1}{p+P},$\n",
    "\n",
    "$\\eta = \\frac{1}{2} \\min{(4GD, \\lambda)},$\n",
    "\n",
    "$\\epsilon = \\frac{1}{(\\eta D)^2},$\n",
    "\n",
    "and an initial matrix $A_0$ $(p + P) \\times (p + P)$\n",
    "\n",
    "$A_0 = \\epsilon I_{p+P}.$\n",
    "\n",
    "Choose $(\\phi, \\Phi)^1 \\in K = \\{ \\gamma \\in \\mathbb{R}^{p+P}, | \\gamma_j | \\leq c, j = 1,\\ldots,p+P \\}$ arbitrarily.\n",
    "\n",
    "for $t=1$ to $T-1$ do\n",
    "\n",
    "&emsp; Predict $\\tilde{X}_t = \\overline{\\phi}(B) X_t + \\overline{\\Phi}(B^s) X_t - \\overline{\\phi}(B)\\overline{\\Phi}(B^s) X_t$\n",
    "\n",
    "&emsp; Observe $X_t$ and compute loss $f_t((\\phi, \\Phi)^t)$\n",
    "\n",
    "&emsp; Let $\\nabla_t = \\nabla f_t((\\phi, \\Phi)^t)$, update $A_t \\leftarrow A_{t-1} + \\nabla_t \\nabla_t^T$ \n",
    "\n",
    "&emsp; Set $(\\phi, \\Phi)^{t+1} \\leftarrow \\Pi^{A_t}_K ((\\phi, \\Phi)^{t} - \\frac{1}{\\eta} A_t^{-1} \\nabla_t)$\n",
    "\n",
    "end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SARMA_ONS:\n",
    "    '''\n",
    "    This class implements Seasonal ARMA Online Newton Step algorithm\n",
    "    '''\n",
    "    def __init__(self, history, order, order_s, period):\n",
    "        self.order = order # AR order p\n",
    "        self.order_s = order_s # Seasonal AR order P\n",
    "        self.period = period # Seasonal period s\n",
    "        \n",
    "        # [X_{t-1}, X_{t-2}, ..., X_{t-(p+s*P)}]\n",
    "        self.hist_window_reversed = np.zeros(order + period * order_s)\n",
    "        trunc = list(reversed(history))[:order + period * order_s]\n",
    "        self.hist_window_reversed[:len(trunc)] = trunc\n",
    "        self.hist_window_reversed = deque(self.hist_window_reversed, maxlen=order + period * order_s)\n",
    "        \n",
    "        self.c = 1\n",
    "        self.X_max = 2\n",
    "        self.D = 2 * self.c * np.sqrt(order + order_s)\n",
    "        self.G = self.D * (self.X_max**2)\n",
    "        self.lambda_ = 1.0 / (order + order_s)\n",
    "        self.eta = 0.5 * min(4 * self.G * self.D, self.lambda_) # learning rate\n",
    "        self.epsilon = 1.0 / (self.eta * self.D)**2\n",
    "        self.A = np.matrix(np.diag([1] * (order + order_s)) * self.epsilon) # hessian matrix\n",
    "        self.gamma = np.matrix(np.random.uniform(-self.c, self.c, (order, 1))) # parameters g_1, g_2, ..., g_p\n",
    "        self.gamma_s = np.matrix(np.random.uniform(-self.c, self.c, (order_s, 1))) # seasonal parameters gs_1, gs_2, ..., gs_P\n",
    "        \n",
    "        \n",
    "    def _compute_backshift(self, polycoef):\n",
    "        '''\n",
    "        Compute a_1 * X_{t-1} + a_2 * X_{t-2} + ... + a_k * X_{t-k}\n",
    "        \n",
    "        inputs:\n",
    "         polycoef = [a_0, a_1, a_2, ..., a_k]\n",
    "         self.hist_window_reversed = [X_{t-1}, X_{t-2}, ..., X_{t-(p+s*P)}]\n",
    "        '''\n",
    "        return np.dot(polycoef, [0] + list(self.hist_window_reversed)[:len(polycoef)-1])\n",
    "        \n",
    "        \n",
    "    def predict(self, gamma_polycoef, gamma_s_polycoef):\n",
    "        '''\n",
    "        X_pred_t = gamma_polynomial(B) X_t + gamma_s_polynomial(B^s) X_t - gamma_polynomial(B) * gamma_s_polynomial(B^s) X_t\n",
    "        where\n",
    "         gamma_polynomial(B) = gamma_1 * B + gamma_2 * B^2 + ... + gamma_p * B^p\n",
    "         gamma_s_polynomial(B^s) = gamma_s_1 * B^s + gamma_s_2 * B^(2s) + ... + gamma_s_P * B^(Ps)\n",
    "         \n",
    "        params:\n",
    "         gamma_polycoef = [gamma_1, gamma_2, ..., gamma_p]\n",
    "         gamma_s_polycoef = [[0]*(s-1), gamma_s_1, [0]*(s-1), gamma_s_2, ... , [0]*(s-1), gamma_s_P]\n",
    "        '''\n",
    "        gamma_polycoef = [0] + gamma_polycoef\n",
    "        gamma_s_polycoef = [0] + gamma_s_polycoef\n",
    "        \n",
    "        X_pred1 = self._compute_backshift(gamma_polycoef)\n",
    "        X_pred2 = self._compute_backshift(gamma_s_polycoef)\n",
    "        \n",
    "        poly_multiply = np.polymul(np.flip(gamma_polycoef), np.flip(gamma_s_polycoef))\n",
    "        poly_multiply = np.flip(poly_multiply)\n",
    "        X_pred3 = self._compute_backshift(poly_multiply)\n",
    "        return X_pred1 + X_pred2 - X_pred3\n",
    "    \n",
    "    \n",
    "    def update_parameters(self, x, x_pred, gamma_polycoef, gamma_s_polycoef):\n",
    "        '''\n",
    "        delta(loss_t)/delta(gamma_i) = -2 * (X_t - X_pred_t) * [B^i * gamma_s_polynomial(B^s)](X_t), i=1,...,p\n",
    "        delta(loss_t)/delta(gamma_s_j) = -2 * (X_t - X_pred_t) * [B^(js) * gamma_polynomial(B)](X_t), j=1,...,P\n",
    "        where\n",
    "         gamma_polynomial(B) = 1 - gamma_1 * B - gamma_2 * B^2 - ... - gamma_p * B^p\n",
    "         gamma_s_polynomial(B^s) = 1 - gamma_s_1 * B^s - gamma_s_2 * B^(2s) - ... - gamma_s_P * B^(Ps)\n",
    "        \n",
    "        params:\n",
    "         gamma_polycoef = [gamma_1, gamma_2, ..., gamma_p]\n",
    "         gamma_s_polycoef = [[0]*(s-1), gamma_s_1, [0]*(s-1), gamma_s_2, ... , [0]*(s-1), gamma_s_P]\n",
    "        '''\n",
    "        gamma_polycoef = [1] + list(-np.array(gamma_polycoef))\n",
    "        gamma_s_polycoef = [1] + list(-np.array(gamma_s_polycoef))\n",
    "        \n",
    "        # compute gradient w.r.t gamma and gamma_s\n",
    "        polynomial_list = [[0]*i + gamma_s_polycoef for i in range(1, self.order+1)]\n",
    "        nabla = [self._compute_backshift(polynomial) for polynomial in polynomial_list]\n",
    "        \n",
    "        polynomial_s_list = [[0]*(i*self.period) + gamma_polycoef for i in range(1, self.order_s+1)]\n",
    "        nabla_s = [self._compute_backshift(polynomial_s) for polynomial_s in polynomial_s_list]\n",
    "        \n",
    "        nabla_all = -2 * (x - x_pred) * np.array(nabla + nabla_s)\n",
    "        \n",
    "        # reshape\n",
    "        nabla_all = nabla_all.reshape(-1,1)\n",
    "        \n",
    "        # update parameters\n",
    "        self.A += np.dot(nabla_all, nabla_all.T)\n",
    "        grad = 1 / self.eta * np.dot(np.linalg.inv(self.A), nabla_all)\n",
    "        self.gamma -= grad[:self.order]\n",
    "        self.gamma_s -= grad[self.order:]\n",
    "    \n",
    "    \n",
    "    def update_history(self, x):\n",
    "        self.hist_window_reversed.appendleft(x)\n",
    "        \n",
    "    \n",
    "    def fit_one_step(self, x):\n",
    "        '''\n",
    "        Run one iteration of the algorithm\n",
    "        \n",
    "        params:\n",
    "         x: float, observation value at t (X_t)\n",
    "        \n",
    "        returns:\n",
    "         x_pred: float, prediction value at t (Xpred_t)\n",
    "         loss: float, squared loss (x - x_pred)^2\n",
    "        '''\n",
    "        gamma_polycoef = list(np.array(self.gamma).squeeze(-1)) # [g_1, ..., g_p]\n",
    "        gamma_s_polycoef = list(np.array(self.gamma_s).squeeze(-1)) # [gs_1, ..., gs_P]\n",
    "        gamma_s_polycoef = list(np.kron(gamma_s_polycoef, [0]*(self.period-1) + [1])) # [[0]*(s-1), gs_1, [0]*(s-1), gs_2, ..., gs_P]\n",
    "        \n",
    "        # predict\n",
    "        x_pred = self.predict(gamma_polycoef, gamma_s_polycoef)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = (x - x_pred)**2\n",
    "        \n",
    "        # update parameters\n",
    "        self.update_parameters(x, x_pred, gamma_polycoef, gamma_s_polycoef)\n",
    "        \n",
    "        # update history\n",
    "        self.update_history(x)\n",
    "        \n",
    "        return x_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Dữ liệu phụ tải workingday miền Bắc năm 2015-082019.csv', \n",
    "                 usecols=list(map(str,range(1,25))), engine='python')\n",
    "MAPEs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc907951f3e4d33a9bab4c240a7e67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,25)):\n",
    "    hour = str(i)\n",
    "    series = df[hour]\n",
    "    series_diff = series.diff().dropna()\n",
    "    split_point = round(len(series) * 0.8)\n",
    "    \n",
    "    # normalize data\n",
    "    mean = series_diff.mean()\n",
    "    std = series_diff.std()\n",
    "    series_diff_normalized = (series_diff - mean) / std\n",
    "    \n",
    "    # train\n",
    "    model = SARMA_ONS([], order=3, order_s=2, period=250)\n",
    "\n",
    "    preds_diff_normalized = []\n",
    "    for x in series_diff_normalized:\n",
    "        x_pred, loss = model.fit_one_step(x)\n",
    "        preds_diff_normalized.append(x_pred)\n",
    "        \n",
    "    # forecast\n",
    "    preds_diff = np.array(preds_diff_normalized) * std + mean\n",
    "    preds = np.r_[[0], series[:-1].values + np.array(preds_diff)]\n",
    "    forecast = pd.Series(preds, index=series.index)[split_point:]\n",
    "\n",
    "    testing = series[split_point:]\n",
    "    \n",
    "    MAPEs.append(np.mean(np.abs((testing - forecast) / testing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05679872860679685, 0.05502600219300754, 0.052509710637228535, 0.050109220669971234, 0.04683890509217262, 0.039710899356154065, 0.03443508317149593, 0.03632499415947579, 0.039822858516609175, 0.04360560007381473, 0.04697241075810682, 0.05303817625300357, 0.056524624640247746, 0.06564048568659717, 0.04891321943308923, 0.0402084665604697, 0.03287686187023267, 0.029562950610582013, 0.03396986222370003, 0.037224901399611994, 0.04330325472493238, 0.051434378419175406, 0.05706941336000028, 0.053607462771670514]\n",
      "0.04606368629950608\n"
     ]
    }
   ],
   "source": [
    "print(MAPEs)\n",
    "print(np.mean(MAPEs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
